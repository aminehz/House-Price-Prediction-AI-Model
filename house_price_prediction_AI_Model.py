# -*- coding: utf-8 -*-
"""House_pricing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tIHDqp8vvQ7IOosBVxD8nIP8f1Y76M2n

**Import necessary Lib**
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
import plotly.express as px
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error, r2_score

"""**Read and understand our Data**"""

housing = pd.read_csv("Housing.csv")
housing.head(10)

housing.info()

housing["price"].describe()

"""# *the Correlations*"""

house_num = housing.select_dtypes(include = ['float64','int64'])
house_num_corr = house_num.corr()['price'][1:] # Exclude self-correlation
top_features = house_num_corr[abs(house_num_corr) > 0.5].sort_values(ascending=False) #Display pearsons correlations coefficient greater than 0.5
print("There is {} strongly correlated values with Price: \n{}".format(len(top_features), top_features))

feature_columns = house_num.columns.difference(['price'])  # Exclude 'price'

# Create pair plots in chunks of 5 features
for i in range(0, len(feature_columns), 5):
    subset_columns = feature_columns[i:i+5]

    # Create a subset DataFrame including 'price' and the selected feature columns
    subset_df = house_num[['price'] + list(subset_columns)]

    # Plot pairwise scatter plots
    sns.pairplot(data=subset_df,
                 x_vars=subset_columns,
                 y_vars=['price'])

    # Add a title to the plot
    plt.suptitle(f'Scatter plots of price vs. {", ".join(subset_columns)}', y=1.02)

    # Display the plot
    plt.show()

"""# **Handling the duplicated**"""

duplicate = housing[housing.duplicated()]
duplicate

duplicated_remove = housing.drop_duplicates()
duplicated_remove

housing.index.is_unique

"""# **Handling The Missing Values**

**finding the missing values**
"""

total = housing.isnull().sum().sort_values(ascending=False)
total_select = total.head(20)
total_select.plot(kind="bar", figsize= (8,6), fontsize=10)

plt.xlabel("Columns", fontsize=20)
plt.ylabel("Count", fontsize = 20)
plt.title("Total Missing Values", fontsize=20)

"""many options to use : drop the missing values"""

#housing.dropna(subset=[""]) #include the attribute name for the attribute that has missing values

#housing.drop("", axis=1) #include attribute for the null values

#we can replace the missing values with mean, median,zero..
# median = housing[""].median()
# median
# housing[""].fillna(median, inplace = True)

housing.tail()

"""# **Handling the outliers**

Uni-variate Analysis : Box plots method
"""

sns.boxplot(x=housing['price'])

sns.boxplot(x=housing['area'])

"""Bi-Variate Analysis"""

price_area = housing.plot.scatter(x='area',
                                  y='price')

"""Deleting the outliers"""

housing.sort_values(by= 'area', ascending=False)[:2] #sort all of the area values and select only the last two.

#remove these two rows
outliers_dropped = housing.drop(housing.index[[7,125]])

new_plot = outliers_dropped.plot.scatter(x='area', y='price')

price_parking = housing.groupby('parking')['price'].mean().reset_index(name ="price").round(2)
price_parking

fig = px.line(price_parking,
              x="parking", y="price"
              )
fig.update_traces(mode='markers+lines')
fig.update_layout(
    title="House Price per Parking",
    xaxis_title="Parking",
    yaxis_title="Price"
)
fig.show()

"""# **Log Transformation**"""

untransformed = sns.displot(housing['price'])

print("skewness: %f" % housing['price'].skew())

log_transformed = np.log(housing['price'])
transformed = sns.displot(log_transformed)

print("skewness: %f" % log_transformed.skew())

"""# **Square root transformation**"""

def plot_square_normal_data():
    data = np.square(np.random.normal(loc=5, size=1000))
    plt.hist(data)
    plt.show()
    return data
data = plot_square_normal_data()

plt.hist(np.sqrt(data))

"""# **Box Cox Transformation**"""

from scipy.stats import boxcox

bc_result = boxcox(housing['price'])
boxcox_price = bc_result[0]
lam = bc_result[1]
lam

housing['price'].hist()

plt.hist(boxcox_price)

"""# **Feature Scaling**
Normalize the data
"""

norm_data = MinMaxScaler().fit_transform(house_num)
norm_data
x_norm = house_num.drop(columns=['price'])
y_norm = house_num['price']
x_normalized = MinMaxScaler().fit_transform(x_norm)
# we have to reshape the y_norm because its 1d
y_normalized = y_norm.values.reshape(-1,1)
y_normalized = MinMaxScaler().fit_transform(y_normalized).ravel()

"""Standardize the data"""

# Standardize features
x = house_num.drop(columns=['price'])
y = house_num['price']

scaler = StandardScaler()
x_standardized = scaler.fit_transform(x)

# Since `y` is a 1D array, we need to reshape it
y_standardized = y.values.reshape(-1, 1)
y_standardized = scaler.fit_transform(y_standardized).ravel()

"""# **Machine learning Model**"""

x_train, x_test, y_train, y_test = train_test_split(x_standardized, y_standardized, test_size=0.25, random_state=42)
model = LinearRegression()
model.fit(x_train,y_train)

predictions= model.predict(x_test)
mse = mean_squared_error(y_test, predictions)
print(mse)

# Calculate additional metrics
mae = mean_absolute_error(y_test, predictions)
r2 = r2_score(y_test, predictions)
rmse = np.sqrt(mean_squared_error(y_test, predictions))

print(f'Mean Absolute Error: {mae}')
print(f'R-squared: {r2}')
print(f'Root Mean Squared Error: {rmse}')

# Plot residuals
plt.scatter(y_test, y_test - predictions)
plt.axhline(y=0, color='r', linestyle='--')
plt.xlabel('Actual Price')
plt.ylabel('Residuals')
plt.title('Residuals vs Actual Price')
plt.show()

